Absolutely. Here‚Äôs the updated version with that note added clearly but concisely:

---

# hand-teleop

**hand-teleop** turns your webcam into real-time robot joint positions ‚Äî no servers, just pure Python.

Designed for [LeRobot](https://github.com/huggingface/lerobot), it runs fast, smooth, and locally.

## Highlights

* ‚ö° **Wilor model** (GPU) ‚Äî accurate and real-time (currently the only fully working backend)
* üß© **AprilTag-based fingertip tracking** (experimental)
* üñêÔ∏è Direct joint outputs ‚Äî no inverse kinematics required
* üîÑ Built-in Kalman smoothing for low-jitter motion
* üßµ Low-latency threading: tracking runs in the background
* üß© Plug-and-play with LeRobot

---

## Installation

### ‚úÖ Recommended (Wilor ‚Äì GPU-based, CUDA required)

```bash
pip install "hand-teleop @ git+https://github.com/joeclinton1/hand-teleop.git#egg=hand-teleop[wilor]"
```

> ‚úÖ **Works well out of the box**
> ‚ö†Ô∏è **Requires GPU with CUDA**

---

### ‚ö†Ô∏è Experimental CPU-based Backends

```bash
pip install "hand-teleop @ git+https://github.com/joeclinton1/hand-teleop.git#egg=hand-teleop[mediapipe]"
pip install "hand-teleop @ git+https://github.com/joeclinton1/hand-teleop.git#egg=hand-teleop[apriltag]"
```

> üß™ These are **almost working**, but not quite stable yet.
> üôè **PRs welcome** to help fix or improve them!

---

### üõ† Development Install

```bash
conda create -n hand-teleop python=3.10 -y
conda activate hand-teleop
conda install -c conda-forge ffmpeg

git clone https://github.com/joeclinton1/hand-teleop.git
cd hand-teleop
pip install -e ".[wilor]"
```

---

### Optional (for forward/inverse kinematics)

```bash
conda install -c conda-forge pinocchio
```

---

## AprilTag Setup (for cube-based tracking)

If you're experimenting with the `apriltag` model, here's the intended tag layout:

### Cube Tag Layout

Each cube is 2.5 cm with 1.8 cm-wide tags.

| Face   | Index Tags | Thumb Tags |
| ------ | ---------- | ---------- |
| Front  | 0          | 5          |
| Left   | 1          | 6          |
| Right  | 2          | 7          |
| Top    | 3          | 8          |
| Bottom | 4          | 9          |

```
      +------+       
      |  3   |     ‚Üë Top
 +----+------+----+
 |  1 |  0   |  2 |   ‚Üí Front = 0
 +----+------+----+
      |  4   |     ‚Üì Bottom
      +------+
```

* Only **one visible tag per cube** is needed.
* Automatically selects the best visible tag.

---

### Assets

* STL: `assets/finger_tip_cubes.stl`
* Printable tags: `assets/tag25h9_0-9,0-9/`

---

## Basic Usage

```python
from hand_teleop import HandTracker

tracker = HandTracker(model="wilor", hand="right", cam_idx=0)
tracker.start()

while True:
    joints = tracker.get_joint_positions()
    robot.set_joint_positions(joints)
```

---

## Demo

```bash
python main.py
```

### Command-line options

* `--model wilor` ‚Äî Hand model to use
* `--fps 30` ‚Äî Frame rate (default: 60)
* `--quiet` ‚Äî Silence console output
* `--no-joint` ‚Äî Output raw gripper pose

---

## Controls

* `p` ‚Äî Pause/resume
* `space` ‚Äî Hold to realign

---

## License

Apache 2.0